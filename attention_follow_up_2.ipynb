{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "attention_follow_up_2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPyFc6UDSF0gX1b1OOEg3Gs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Chuck2Win/attention/blob/5_11/attention_follow_up_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ldWZU2pOGp4l",
        "colab_type": "code",
        "outputId": "cc827d90-fbf4-4f77-f27f-62251130e2b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        }
      },
      "source": [
        "import numpy as np\n",
        "import torch \n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchtext\n",
        "from gensim.models import Word2Vec\n",
        "import nltk\n",
        "import os\n",
        "from google.colab import files\n",
        "from google.colab import drive\n",
        "from matplotlib import pyplot as plt\n",
        "import json\n",
        "# google drive와 연동\n",
        "drive.mount('/content/gdrive')\n",
        "print(os.getcwd())\n",
        "# os.chdir('..') ..은 상위 폴더로 이동\n",
        "os.chdir('./gdrive/My Drive/attention_from_master_')\n",
        "print(os.getcwd())\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n",
            "/content\n",
            "/content/gdrive/My Drive/attention_from_master_\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "erd2TcEmjqDM",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 114
        },
        "outputId": "b4e61517-7df2-4a5e-e37b-db40c4a07d00"
      },
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-a52a6774-437a-40e8-9959-9cdf4fe7f7b5\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-a52a6774-437a-40e8-9959-9cdf4fe7f7b5\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving ratings_test.txt to ratings_test.txt\n",
            "Saving ratings_train.txt to ratings_train.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0HB072iG_zr",
        "colab_type": "code",
        "outputId": "39ace4f7-2fb8-40d1-aaf3-c47f8166567a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        }
      },
      "source": [
        "! pip install sentencepiece\n",
        "import sentencepiece as spm\n",
        "# testing\n",
        "vocab_file = \"./kowiki.model\"\n",
        "vocab = spm.SentencePieceProcessor()\n",
        "vocab.load(vocab_file)\n",
        "\n",
        "lines = [\n",
        "  \"겨울이 되어서 날씨가 무척 추워요.\",\n",
        "  \"이번 성탄절은 화이트 크리스마스가 될까요?\",\n",
        "  \"겨울에 감기 조심하시고 행복한 연말 되세요.\"\n",
        "]\n",
        "inputs=[]\n",
        "for line in lines:\n",
        "  pieces = vocab.encode_as_pieces(line)\n",
        "  ids = vocab.encode_as_ids(line)\n",
        "  inputs.append(torch.tensor(ids))\n",
        "  print(line)\n",
        "  print(pieces)\n",
        "  print(ids)\n",
        "  print() # 단어를 subword 단위로 잘 쪼개는것을 확인할 수 있습니다."
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/98/2c/8df20f3ac6c22ac224fff307ebc102818206c53fc454ecd37d8ac2060df5/sentencepiece-0.1.86-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\r\u001b[K     |▎                               | 10kB 21.5MB/s eta 0:00:01\r\u001b[K     |▋                               | 20kB 26.9MB/s eta 0:00:01\r\u001b[K     |█                               | 30kB 12.0MB/s eta 0:00:01\r\u001b[K     |█▎                              | 40kB 12.0MB/s eta 0:00:01\r\u001b[K     |█▋                              | 51kB 9.4MB/s eta 0:00:01\r\u001b[K     |██                              | 61kB 9.7MB/s eta 0:00:01\r\u001b[K     |██▏                             | 71kB 9.7MB/s eta 0:00:01\r\u001b[K     |██▌                             | 81kB 9.2MB/s eta 0:00:01\r\u001b[K     |██▉                             | 92kB 9.6MB/s eta 0:00:01\r\u001b[K     |███▏                            | 102kB 9.6MB/s eta 0:00:01\r\u001b[K     |███▌                            | 112kB 9.6MB/s eta 0:00:01\r\u001b[K     |███▉                            | 122kB 9.6MB/s eta 0:00:01\r\u001b[K     |████                            | 133kB 9.6MB/s eta 0:00:01\r\u001b[K     |████▍                           | 143kB 9.6MB/s eta 0:00:01\r\u001b[K     |████▊                           | 153kB 9.6MB/s eta 0:00:01\r\u001b[K     |█████                           | 163kB 9.6MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 174kB 9.6MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 184kB 9.6MB/s eta 0:00:01\r\u001b[K     |██████                          | 194kB 9.6MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 204kB 9.6MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 215kB 9.6MB/s eta 0:00:01\r\u001b[K     |███████                         | 225kB 9.6MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 235kB 9.6MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 245kB 9.6MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 256kB 9.6MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 266kB 9.6MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 276kB 9.6MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 286kB 9.6MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 296kB 9.6MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 307kB 9.6MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 317kB 9.6MB/s eta 0:00:01\r\u001b[K     |██████████                      | 327kB 9.6MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 337kB 9.6MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 348kB 9.6MB/s eta 0:00:01\r\u001b[K     |███████████                     | 358kB 9.6MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 368kB 9.6MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 378kB 9.6MB/s eta 0:00:01\r\u001b[K     |████████████                    | 389kB 9.6MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 399kB 9.6MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 409kB 9.6MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 419kB 9.6MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 430kB 9.6MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 440kB 9.6MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 450kB 9.6MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 460kB 9.6MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 471kB 9.6MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 481kB 9.6MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 491kB 9.6MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 501kB 9.6MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 512kB 9.6MB/s eta 0:00:01\r\u001b[K     |████████████████                | 522kB 9.6MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 532kB 9.6MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 542kB 9.6MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 552kB 9.6MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 563kB 9.6MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 573kB 9.6MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 583kB 9.6MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 593kB 9.6MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 604kB 9.6MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 614kB 9.6MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 624kB 9.6MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 634kB 9.6MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 645kB 9.6MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 655kB 9.6MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 665kB 9.6MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 675kB 9.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 686kB 9.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 696kB 9.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 706kB 9.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 716kB 9.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 727kB 9.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 737kB 9.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 747kB 9.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 757kB 9.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 768kB 9.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 778kB 9.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 788kB 9.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 798kB 9.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 808kB 9.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 819kB 9.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 829kB 9.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 839kB 9.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 849kB 9.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 860kB 9.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 870kB 9.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 880kB 9.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 890kB 9.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 901kB 9.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 911kB 9.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 921kB 9.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 931kB 9.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 942kB 9.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 952kB 9.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 962kB 9.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 972kB 9.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 983kB 9.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 993kB 9.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 1.0MB 9.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 1.0MB 9.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 1.0MB 9.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 1.0MB 9.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.0MB 9.6MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.86\n",
            "겨울이 되어서 날씨가 무척 추워요.\n",
            "['▁겨울', '이', '▁되어', '서', '▁날', '씨', '가', '▁무', '척', '▁추', '워', '요', '.']\n",
            "[3099, 3582, 604, 3596, 684, 4009, 3593, 109, 4189, 206, 3951, 3754, 3584]\n",
            "\n",
            "이번 성탄절은 화이트 크리스마스가 될까요?\n",
            "['▁이번', '▁성', '탄', '절', '은', '▁화', '이트', '▁크리스', '마', '스가', '▁될', '까', '요', '?']\n",
            "[3228, 86, 3961, 3917, 3598, 264, 669, 1940, 3658, 777, 1442, 3788, 3754, 4243]\n",
            "\n",
            "겨울에 감기 조심하시고 행복한 연말 되세요.\n",
            "['▁겨울', '에', '▁감', '기', '▁조', '심', '하', '시', '고', '▁행', '복', '한', '▁연', '말', '▁되', '세', '요', '.']\n",
            "[3099, 3585, 208, 3599, 53, 3826, 3590, 3608, 3594, 235, 3865, 3597, 61, 3817, 448, 3676, 3754, 3584]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o4lk7-6fHEDR",
        "colab_type": "code",
        "outputId": "7dc39126-10cf-4395-b146-802199c67f0a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "print(len(vocab)) # 8007\n",
        "print(len(ids))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8007\n",
            "18\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_MIYQwdNUXJ",
        "colab_type": "code",
        "outputId": "cef81a14-8fd7-4cba-eb11-3c5a3867c6ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        }
      },
      "source": [
        "# 입력 길이가 다르므로 입력 최대 길이에 맟춰 padding(0)을 추가 해 줌\n",
        "inputs = torch.nn.utils.rnn.pad_sequence(inputs, batch_first=True, padding_value=0)\n",
        "print(inputs)\n",
        "print(inputs.shape) # 3, 18 -> 가장 긴 문장을 기준으로 padding 해준다."
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[3099, 3582,  604, 3596,  684, 4009, 3593,  109, 4189,  206, 3951, 3754,\n",
            "         3584,    0,    0,    0,    0,    0],\n",
            "        [3228,   86, 3961, 3917, 3598,  264,  669, 1940, 3658,  777, 1442, 3788,\n",
            "         3754, 4243,    0,    0,    0,    0],\n",
            "        [3099, 3585,  208, 3599,   53, 3826, 3590, 3608, 3594,  235, 3865, 3597,\n",
            "           61, 3817,  448, 3676, 3754, 3584]])\n",
            "torch.Size([3, 18])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "deyDJ6gRI5_C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# positional encoding을 해줘야한다.\n",
        "def positional_encoding(seq_len,embedding_dim):\n",
        "    # input shape : [n,seq_len]\n",
        "    #output=torch.zeros((seq_len+1,embedding_dim),device=device)\n",
        "    output=torch.zeros((seq_len,embedding_dim),device=device)\n",
        "    def for_insert(output):\n",
        "        m,n=output.shape\n",
        "        for i in range(m):\n",
        "            for j in range(n):\n",
        "                output[i,j]=i/10000**(2*j/embedding_dim)\n",
        "        return output\n",
        "    pe=for_insert(output)\n",
        "    pe[:,0::2]=torch.sin(pe[:,0::2])\n",
        "    pe[:,1::2]=torch.cos(pe[:,1::2])\n",
        "    # pe[0,:]=0. 없애고 진행해보자\n",
        "    return pe"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uPNQkNjiL_in",
        "colab_type": "code",
        "outputId": "3ac080fe-af14-4c88-c8e6-160a7a18f44c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        }
      },
      "source": [
        "device='cpu'\n",
        "positional_encoding(64,300)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.0000e+00,  1.0000e+00,  0.0000e+00,  ...,  1.0000e+00,\n",
              "          0.0000e+00,  1.0000e+00],\n",
              "        [ 8.4147e-01,  5.8943e-01,  7.7356e-01,  ...,  1.0000e+00,\n",
              "          1.1307e-08,  1.0000e+00],\n",
              "        [ 9.0930e-01, -3.0515e-01,  9.8045e-01,  ...,  1.0000e+00,\n",
              "          2.2613e-08,  1.0000e+00],\n",
              "        ...,\n",
              "        [-9.6612e-01,  6.8334e-01, -5.1718e-01,  ...,  1.0000e+00,\n",
              "          6.8970e-07,  1.0000e+00],\n",
              "        [-7.3918e-01, -1.8701e-01, -9.8982e-01,  ...,  1.0000e+00,\n",
              "          7.0101e-07,  1.0000e+00],\n",
              "        [ 1.6736e-01, -9.0380e-01, -7.3737e-01,  ...,  1.0000e+00,\n",
              "          7.1232e-07,  1.0000e+00]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xCtihPHIMg7Q",
        "colab_type": "code",
        "outputId": "d91a3c5b-74ab-4038-a173-d4d5d3590484",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "# 이를 토대로 positional embedding을 구한다.\n",
        "'''\n",
        "위에서 구해진 position encoding 값을 이용해 position embedding을 생성합니다. \n",
        "학습되는 값이 아니므로 freeze옵션을 True로 설정 합니다.\n",
        "입력 inputs과 동일한 크기를 갖는 positions값을 구합니다.\n",
        "input값 중 pad(0)값을 찾습니다.\n",
        "positions값중 pad부분은 0으로 변경 합니다. (mask를 활용)\n",
        "positions값에 해당하는 embedding값을 구합니다\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n위에서 구해진 position encoding 값을 이용해 position embedding을 생성합니다. \\n학습되는 값이 아니므로 freeze옵션을 True로 설정 합니다.\\n입력 inputs과 동일한 크기를 갖는 positions값을 구합니다.\\ninput값 중 pad(0)값을 찾습니다.\\npositions값중 pad부분은 0으로 변경 합니다. (mask를 활용)\\npositions값에 해당하는 embedding값을 구합니다\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n위에서 구해진 position encoding 값을 이용해 position embedding을 생성합니다. \\n학습되는 값이 아니므로 freeze옵션을 True로 설정 합니다.\\n입력 inputs과 동일한 크기를 갖는 positions값을 구합니다.\\ninput값 중 pad(0)값을 찾습니다.\\npositions값중 pad부분은 0으로 변경 합니다. (mask를 활용)\\npositions값에 해당하는 embedding값을 구합니다\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQmJPNFQMyin",
        "colab_type": "code",
        "outputId": "f63ec3dc-2e98-4d21-f533-3f2fd8780dd5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        }
      },
      "source": [
        "############################# input embedding ##########################################\n",
        "n_vocab=len(vocab)\n",
        "embedding=128\n",
        "seq_len=64 # 아싸리 크게 하면 되겠네. 딱 타이트하게 하지 말고...\n",
        "Embedding=nn.Embedding(n_vocab,embedding,padding_idx=0)\n",
        "Embedding.weight.required_grad=False\n",
        "inputs_embedding=Embedding(inputs) \n",
        "############################# positional embedding ##########################################\n",
        "pos_encoding=positional_encoding(seq_len,embedding)\n",
        "positional_embedding=nn.Embedding.from_pretrained(pos_encoding,freeze=True)\n",
        "positions=torch.arange(inputs.size(1)).expand(inputs.size(0),inputs.size(1))+1 # inputs size : n,seq_len # 0부터 시작해서 1을 더한 것이다.\n",
        "print(positions)\n",
        "pos_mask=inputs.eq(0) # mask shape : n,seq_len : 3, 18\n",
        "positions.masked_fill_(pos_mask,0)  # (어차피 0에는 무엇을 곱해도 0이 되니깐)->아니지. 그리고 1을 더했다.. 그전에\n",
        "print(positions)\n",
        "pos_embedding=positional_embedding(positions)\n",
        "print(pos_embedding[1]) # 보게 되면 0에 해당하는 부분은 0,1,0,1로 반복되고 있다."
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18],\n",
            "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18],\n",
            "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18]])\n",
            "tensor([[ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13,  0,  0,  0,  0,  0],\n",
            "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14,  0,  0,  0,  0],\n",
            "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18]])\n",
            "tensor([[ 8.4147e-01,  6.4791e-01,  6.8156e-01,  ...,  1.0000e+00,\n",
            "          1.3335e-08,  1.0000e+00],\n",
            "        [ 9.0930e-01, -1.6044e-01,  9.9748e-01,  ...,  1.0000e+00,\n",
            "          2.6670e-08,  1.0000e+00],\n",
            "        [ 1.4112e-01, -8.5580e-01,  7.7827e-01,  ...,  1.0000e+00,\n",
            "          4.0006e-08,  1.0000e+00],\n",
            "        ...,\n",
            "        [ 0.0000e+00,  1.0000e+00,  0.0000e+00,  ...,  1.0000e+00,\n",
            "          0.0000e+00,  1.0000e+00],\n",
            "        [ 0.0000e+00,  1.0000e+00,  0.0000e+00,  ...,  1.0000e+00,\n",
            "          0.0000e+00,  1.0000e+00],\n",
            "        [ 0.0000e+00,  1.0000e+00,  0.0000e+00,  ...,  1.0000e+00,\n",
            "          0.0000e+00,  1.0000e+00]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "422ILQbeSWwl",
        "colab_type": "code",
        "outputId": "446b9f22-e768-4a2f-8a92-e73de33ea9be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        }
      },
      "source": [
        "# positional embedding과 token embedding을 더해야지\n",
        "input_sums=inputs_embedding+pos_embedding \n",
        "# anyway, padding이 된 부분에 해당되는 부분이 0 값이 된 것은 아니다.. -> 그렇기 때문에...\n",
        "inputs[0]\n",
        "input_sums[0]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-1.1057, -0.2500, -1.1481,  ...,  3.0691,  0.6567,  1.3464],\n",
              "        [ 2.7157, -0.1901,  1.6571,  ..., -0.9450,  0.7493, -0.4445],\n",
              "        [-1.1990, -0.3164,  0.7477,  ...,  0.7196, -1.5468,  0.2722],\n",
              "        ...,\n",
              "        [ 0.0000,  1.0000,  0.0000,  ...,  1.0000,  0.0000,  1.0000],\n",
              "        [ 0.0000,  1.0000,  0.0000,  ...,  1.0000,  0.0000,  1.0000],\n",
              "        [ 0.0000,  1.0000,  0.0000,  ...,  1.0000,  0.0000,  1.0000]],\n",
              "       grad_fn=<SelectBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5LFPW0tIU0Fl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Q=input_sums # shape : 3, 18, 128\n",
        "K=input_sums # inputs shape : 3, 18\n",
        "V=input_sums\n",
        "# inputs.shape : batch_size, seq_len\n",
        "attention_mask=inputs.eq(0).unsqueeze(1).expand(Q.size(0),Q.size(1),K.size(1)) # shape : 3, 18, 18\n",
        "# print(get_attention_pad_mask(Q,K))\n",
        "# print(attention_mask[0].shape)\n",
        "# print(attention_mask[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ev-98oGKWfTU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class scaled_dot_product_attention(nn.Module): # 고민 요소\n",
        "    # 나의 초안에서 attention 함수를 차용해 옴\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "               \n",
        "    def forward(self,Q,K,V,attention_mask):\n",
        "        # Q,K - shape [n,seq_len,dk] // V - shape [n,seq_len,dv]\n",
        "        # self attention 이므로 dk=dv(=embedding)\n",
        "        scores=Q.matmul(K.transpose(-2,-1))/torch.sqrt(torch.tensor(Q.shape[-1]).float())\n",
        "        # 여기에서 attention mask는 padding이 된 부분을 0으로 처리한 것\n",
        "        # attention mask shape : n,seq_len,seq_len\n",
        "        # 00011\n",
        "        # 00011\n",
        "        # 00011\n",
        "        # 00011\n",
        "        # 00011 \n",
        "        # 요론 모양\n",
        "        scores.masked_fill_(attention_mask,-1e-9)\n",
        "        weight=F.softmax(scores,dim=-1)\n",
        "        # weight : n, seq_len, seq_len\n",
        "        attention_score=weight.matmul(V)\n",
        "        # attention score : n,seq_len,dv\n",
        "        return attention_score, weight"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aW--ols2aRTC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 나는 multi head attention을 안했었는데, 병렬로 처리하기 위해선 더 좋으니깐\n",
        "# 쩐다...★\n",
        "class multi_head_attention(nn.Module): # 고민 요소\n",
        "    # 나의 초안에서 attention 함수를 차용해 옴\n",
        "    def __init__(self,batch_size,n_head,d_head,d_k):\n",
        "        super().__init__()\n",
        "        self.batch_size=batch_size\n",
        "        self.n_head=n_head\n",
        "        self.d_head=d_head\n",
        "        self.d_k=d_k\n",
        "        self.W_Q=nn.Linear(d_k,n_head*d_head)\n",
        "        self.W_K=nn.Linear(d_k,n_head*d_head)\n",
        "        self.W_V=nn.Linear(d_k,n_head*d_head)\n",
        "        self.W_0=nn.Linear(n_head*d_head,n_head*d_head) # n_head*d_head = embedding\n",
        "        self.sdpa=scaled_dot_product_attention()\n",
        "    def forward(self,Q,K,V,attention_mask):\n",
        "        # Q,K - shape [n,seq_len,dk] // V - shape [n,seq_len,dv]\n",
        "        # self attention 이므로 dk=dv(=embedding)\n",
        "        # attention_mask shape : [n,seq_len,seq_len]\n",
        "        qs=self.W_Q(Q).reshape(self.batch_size,-1,self.n_head,self.d_head).transpose(1,2) # ★\n",
        "        ks=self.W_K(K).reshape(self.batch_size,-1,self.n_head,self.d_head).transpose(1,2)\n",
        "        vs=self.W_V(V).reshape(self.batch_size,-1,self.n_head,self.d_head).transpose(1,2)\n",
        "        attention_mask=attention_mask.unsqueeze(1).repeat(1,self.n_head,1,1) # attention_mask shape : [n,self.n_head,seq_len,seq_len] <- mask도 동일하게 multi head로 확장시켜 나가야지\n",
        "        context,weight=self.sdpa(qs,ks,vs,attention_mask) # context shape : n, n_head, seq_len, d_head\n",
        "        context=context.transpose(1,2).reshape(self.batch_size,-1,self.n_head*self.d_head)\n",
        "        output=self.W_0(context)\n",
        "        return output, weight"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KqZA3ucrbm8C",
        "colab_type": "code",
        "outputId": "bcd7ea6e-c520-4d62-c54a-df4ae8e37907",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "mm=multi_head_attention(3,2,64,128)\n",
        "mm.forward(Q,K,V,attention_mask)[0].shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 18, 128])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 18, 128])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sBJmZemFfWDt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# masked multi_head attention\n",
        "def get_attention_decoder_mask(seq):\n",
        "    # seq : batch_size, query_seq_len\n",
        "    subsequent_mask=torch.ones_like(seq).unsqueeze(-1).expand(seq.size(0),seq.size(1),seq.size(1))\n",
        "    # mask : batch_size, seq_len, seq_len\n",
        "    mask=subsequent_mask.triu(diagonal=1)\n",
        "    return mask   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yutc5dVfpjx0",
        "colab_type": "code",
        "outputId": "8cd2590c-ccc6-4c08-ac31-6a857007b5a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        }
      },
      "source": [
        "attn_dec_mask=get_attention_decoder_mask(inputs)\n",
        "attn_dec_mask.shape\n",
        "attn_dec_mask[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              "        [0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              "        [0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              "        [0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              "        [0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              "        [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k59OKTT3qbbM",
        "colab_type": "code",
        "outputId": "4fa3080f-2e7c-4b17-ca04-2f634e5bb417",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 685
        }
      },
      "source": [
        "attn_pad_mask=inputs.eq(0).unsqueeze(1).expand(Q.size(0),Q.size(1),K.size(1))\n",
        "print(attn_pad_mask[1])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False, False,  True,  True,  True,  True],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False, False,  True,  True,  True,  True],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False, False,  True,  True,  True,  True],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False, False,  True,  True,  True,  True],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False, False,  True,  True,  True,  True],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False, False,  True,  True,  True,  True],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False, False,  True,  True,  True,  True],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False, False,  True,  True,  True,  True],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False, False,  True,  True,  True,  True],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False, False,  True,  True,  True,  True],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False, False,  True,  True,  True,  True],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False, False,  True,  True,  True,  True],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False, False,  True,  True,  True,  True],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False, False,  True,  True,  True,  True],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False, False,  True,  True,  True,  True],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False, False,  True,  True,  True,  True],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False, False,  True,  True,  True,  True],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False, False,  True,  True,  True,  True]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DFaFuUOf3-D8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d852491f-0948-4ec3-f432-266c8f707ca0"
      },
      "source": [
        "# pad mask와 decoder mask를 합쳐야 한다.\n",
        "attention_decoder_mask=get_attention_decoder_mask(inputs)\n",
        "attn_mask=torch.gt((attn_pad_mask+attention_decoder_mask),0) # element wise로 0보다 크면 True\n",
        "\n",
        "print(attn_mask.long())"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[[0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "         [0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "         [0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "         [0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "         [0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "         [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "         [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "         [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1],\n",
            "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1],\n",
            "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1],\n",
            "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1],\n",
            "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1],\n",
            "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1],\n",
            "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1],\n",
            "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1]],\n",
            "\n",
            "        [[0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "         [0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "         [0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "         [0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "         [0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "         [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "         [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "         [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1],\n",
            "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1],\n",
            "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1],\n",
            "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1],\n",
            "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1],\n",
            "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1],\n",
            "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1],\n",
            "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1]],\n",
            "\n",
            "        [[0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "         [0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "         [0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "         [0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "         [0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "         [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "         [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "         [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1],\n",
            "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1],\n",
            "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1],\n",
            "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1],\n",
            "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1],\n",
            "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1],\n",
            "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
            "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "td2Wp6n-wzXR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" feed forward \"\"\"\n",
        "class PoswiseFeedForwardNet(nn.Module):\n",
        "    def __init__(self, d_hidn):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv1d(in_channels=d_hidn, out_channels=d_hidn * 4, kernel_size=1)\n",
        "        self.conv2 = nn.Conv1d(in_channels=d_hidn * 4, out_channels=d_hidn, kernel_size=1)\n",
        "        self.active = F.gelu\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        # (batch size, d_ff, n_seq)\n",
        "        output = self.active(self.conv1(inputs.transpose(1, 2)))\n",
        "        # (bs, n_seq, d_hidn)\n",
        "        output = self.conv2(output).transpose(1, 2)\n",
        "        # (bs, n_seq, d_hidn)\n",
        "        return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g6d6auS76HDM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ? torch.gt()\n",
        "attn_mask=torch.gt((attention_pad_mask+attention_decoder_mask),0) # torch.gt(input,other)=> input>other인 경우 element wise\n",
        "print(attn_mask[0].long())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gYkdHZZI8NyT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Config(dict): \n",
        "    __getattr__ = dict.__getitem__\n",
        "    __setattr__ = dict.__setitem__\n",
        "\n",
        "    @classmethod\n",
        "    def load(cls, file):\n",
        "        with open(file, 'r') as f:\n",
        "            config = json.loads(f.read())\n",
        "            return Config(config)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "irfLmQaE8cOa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "config=Config({\"n_enc_vocab\": len(vocab),\n",
        "    \"n_dec_vocab\": len(vocab),\n",
        "    \"n_enc_seq\": 256,\n",
        "    \"n_dec_seq\": 256,\n",
        "    \"n_layer\": 6,\n",
        "    \"d_hidden\": 256,\n",
        "    \"padding_idx\": 0,\n",
        "    \"d_feedforward\": 1024,\n",
        "    \"n_head\": 4,\n",
        "    \"d_head\": 64,\n",
        "    \"dropout\": 0.1,\n",
        "    \"layer_norm_epsilon\": 1e-12\n",
        "})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cTmvJVMf83RC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "1bac79af-dfb0-4e32-d928-362f61375b51"
      },
      "source": [
        "config['dropout']"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kpRYVX4lX9sU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# transformer 2차\n",
        "class scaled_dot_product_attention(nn.Module): # 고민 요소\n",
        "    def __init__(self,config):\n",
        "        super().__init__()\n",
        "        self.dropout=nn.Dropout(config['dropout'])      \n",
        "    def forward(self,Q,K,V,attention_mask):\n",
        "        # Q,K - shape [n,seq_len,dk] // V - shape [n,seq_len,dv]\n",
        "        # self attention 이므로 dk=dv(=embedding)\n",
        "        scores=Q.matmul(K.transpose(-2,-1))/torch.sqrt(torch.tensor(Q.shape[-1]).float())\n",
        "        scores.masked_fill_(attention_mask,-1e-9)\n",
        "        weight=self.dropout(F.softmax(scores,dim=-1))\n",
        "\n",
        "        # weight : n, seq_len, seq_len\n",
        "        attention_score=weight.matmul(V)\n",
        "        # attention score : n,seq_len,dv\n",
        "        return attention_score, weight"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pQxDFgVNZbZ_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class multi_head_attention(nn.Module): # 고민 요소\n",
        "    # 나의 초안에서 attention 함수를 차용해 옴\n",
        "    def __init__(self,config):\n",
        "        \n",
        "        super().__init__()\n",
        "        \n",
        "        self.n_head=config['n_head']\n",
        "        self.d_head=config['d_head']\n",
        "        self.d_k=config['d_hidden']\n",
        "        self.W_Q=nn.Linear(self.d_k,self.n_head*self.d_head)\n",
        "        self.W_K=nn.Linear(self.d_k,self.n_head*self.d_head)\n",
        "        self.W_V=nn.Linear(self.d_k,self.n_head*self.d_head)\n",
        "        self.W_0=nn.Linear(self.n_head*self.d_head,self.n_head*self.d_head) # n_head*d_head = embedding\n",
        "        self.sdpa=scaled_dot_product_attention(config)\n",
        "        self.dropout=nn.Dropout(config['dropout'])\n",
        "    def forward(self,Q,K,V,attention_mask):\n",
        "        # Q,K - shape [n,seq_len,dk] // V - shape [n,seq_len,dv]\n",
        "        # self attention 이므로 dk=dv(=embedding)\n",
        "        # attention_mask shape : [n,seq_len,seq_len]\n",
        "        self.batch_size=Q.size(0)\n",
        "        qs=self.W_Q(Q).reshape(self.batch_size,-1,self.n_head,self.d_head).transpose(1,2) # ★\n",
        "        ks=self.W_K(K).reshape(self.batch_size,-1,self.n_head,self.d_head).transpose(1,2)\n",
        "        vs=self.W_V(V).reshape(self.batch_size,-1,self.n_head,self.d_head).transpose(1,2)\n",
        "        attention_mask=attention_mask.unsqueeze(1).repeat(1,self.n_head,1,1) # attention_mask shape : [n,self.n_head,seq_len,seq_len] <- mask도 동일하게 multi head로 확장시켜 나가야지\n",
        "        context,weight=self.sdpa(qs,ks,vs,attention_mask) # context shape : n, n_head, seq_len, d_head\n",
        "        context=context.transpose(1,2).reshape(self.batch_size,-1,self.n_head*self.d_head)\n",
        "        output=self.W_0(context)\n",
        "        return output, weight"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HSD5IypubEi-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class PoswiseFeedForwardNet(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.d_hidn=config['d_hidden']\n",
        "        self.d_ff=config['d_feedforward']\n",
        "        self.conv1 = nn.Conv1d(in_channels=self.d_hidn, out_channels=self.d_ff, kernel_size=1)\n",
        "        self.conv2 = nn.Conv1d(in_channels=self.d_ff, out_channels=self.d_hidn, kernel_size=1)\n",
        "        self.active = F.gelu\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        # (batch size, d_ff, n_seq)\n",
        "        output = self.active(self.conv1(inputs.transpose(1, 2)))\n",
        "        # (bs, n_seq, d_hidn)\n",
        "        output = self.conv2(output).transpose(1, 2)\n",
        "        # (bs, n_seq, d_hidn)\n",
        "        return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IeVFsDh3dcsQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class EncoderLayer(nn.Module):\n",
        "    def __init__(self,config):\n",
        "        super().__init__()\n",
        "        self.config=config\n",
        "        self.self_attn=multi_head_attention(config)\n",
        "        self.d_hidn=config['d_hidden']\n",
        "        self.layer_norm1=nn.LayerNorm(self.d_hidn,eps=self.config.layer_norm_epsilon)\n",
        "        self.pos_ffn = PoswiseFeedForwardNet(self.config)\n",
        "        self.layer_norm2 = nn.LayerNorm(self.d_hidn, eps=self.config.layer_norm_epsilon)\n",
        "    \n",
        "    def forward(self, inputs, attn_mask):\n",
        "        # (bs, n_enc_seq, d_hidn), (bs, n_head, n_enc_seq, n_enc_seq)\n",
        "        att_outputs, attn_prob = self.self_attn(inputs, inputs, inputs, attn_mask)\n",
        "        att_outputs = self.layer_norm1(inputs + att_outputs) # resnet\n",
        "        # (bs, n_enc_seq, d_hidn)\n",
        "        ffn_outputs = self.pos_ffn(att_outputs)\n",
        "        ffn_outputs = self.layer_norm2(ffn_outputs + att_outputs) # resnet\n",
        "        # (bs, n_enc_seq, d_hidn), (bs, n_head, n_enc_seq, n_enc_seq)\n",
        "        return ffn_outputs, attn_prob"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ho0UUsKfCIy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# positional encoding을 해줘야한다.\n",
        "def get_sinusoid_encoding_table(seq_len,embedding_dim):\n",
        "    # input shape : [n,seq_len]\n",
        "    #output=torch.zeros((seq_len+1,embedding_dim),device=device)\n",
        "    output=torch.zeros((seq_len,embedding_dim),device=device)\n",
        "    def for_insert(output):\n",
        "        m,n=output.shape\n",
        "        for i in range(m):\n",
        "            for j in range(n):\n",
        "                output[i,j]=i/10000**(2*j/embedding_dim)\n",
        "        return output\n",
        "    pe=for_insert(output)\n",
        "    pe[:,0::2]=torch.sin(pe[:,0::2])\n",
        "    pe[:,1::2]=torch.cos(pe[:,1::2])\n",
        "    # pe[0,:]=0. 없애고 진행해보자\n",
        "    return pe"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-rEwGJUdn6f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "\n",
        "        self.enc_emb = nn.Embedding(self.config.n_enc_vocab, self.config.d_hidden)\n",
        "        sinusoid_table = torch.FloatTensor(get_sinusoid_encoding_table(self.config.n_enc_seq + 1, self.config.d_hidden))\n",
        "        self.pos_emb = nn.Embedding.from_pretrained(sinusoid_table, freeze=True)\n",
        "        self.layers = nn.ModuleList([EncoderLayer(self.config) for _ in range(self.config.n_layer)])\n",
        "        # Module list는 connect되어 있지 않다.\n",
        "    def forward(self, inputs):\n",
        "        positions = torch.arange(inputs.size(1), device=inputs.device, dtype=inputs.dtype).expand(inputs.size(0), inputs.size(1)).contiguous() + 1\n",
        "        pos_mask = inputs.eq(self.config.i_pad)\n",
        "        positions.masked_fill_(pos_mask, 0)\n",
        "\n",
        "        # (bs, n_enc_seq, d_hidn)\n",
        "        outputs = self.enc_emb(inputs) + self.pos_emb(positions)\n",
        "\n",
        "        # (bs, n_enc_seq, n_enc_seq)\n",
        "        attn_mask = inputs.eq(self.config.i_pad).unsqueeze(1).expand(inputs.size(0),inputs.size(1),inputs.size(1))\n",
        "\n",
        "        attn_probs = []\n",
        "        for layer in self.layers:\n",
        "            # (bs, n_enc_seq, d_hidn), (bs, n_head, n_enc_seq, n_enc_seq)\n",
        "            outputs, attn_prob = layer(outputs, attn_mask)  # sequential로 해도 될 것 같은데\n",
        "            attn_probs.append(attn_prob)\n",
        "        # (bs, n_enc_seq, d_hidn), [(bs, n_head, n_enc_seq, n_enc_seq)]\n",
        "        return outputs, attn_probs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dxb9TDrDhgUs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DecoderLayer(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "        self.self_attn = multi_head_attention(self.config)\n",
        "        self.layer_norm1 = nn.LayerNorm(self.config.d_hidden, eps=self.config.layer_norm_epsilon)\n",
        "        self.dec_enc_attn = multi_head_attention(self.config)\n",
        "        self.layer_norm2 = nn.LayerNorm(self.config.d_hidden, eps=self.config.layer_norm_epsilon)\n",
        "        self.pos_ffn = PoswiseFeedForwardNet(self.config)\n",
        "        self.layer_norm3 = nn.LayerNorm(self.config.d_hidden, eps=self.config.layer_norm_epsilon)\n",
        "    \n",
        "    def forward(self, dec_inputs, enc_outputs, self_attn_mask, dec_enc_attn_mask):\n",
        "        # (bs, n_dec_seq, d_hidn), (bs, n_head, n_dec_seq, n_dec_seq)\n",
        "        self_att_outputs, self_attn_prob = self.self_attn(dec_inputs, dec_inputs, dec_inputs, self_attn_mask)\n",
        "        self_att_outputs = self.layer_norm1(dec_inputs + self_att_outputs)\n",
        "        # (bs, n_dec_seq, d_hidn), (bs, n_head, n_dec_seq, n_enc_seq)\n",
        "        dec_enc_att_outputs, dec_enc_attn_prob = self.dec_enc_attn(self_att_outputs, enc_outputs, enc_outputs, dec_enc_attn_mask)\n",
        "        dec_enc_att_outputs = self.layer_norm2(self_att_outputs + dec_enc_att_outputs)\n",
        "        # (bs, n_dec_seq, d_hidn)\n",
        "        ffn_outputs = self.pos_ffn(dec_enc_att_outputs)\n",
        "        ffn_outputs = self.layer_norm3(dec_enc_att_outputs + ffn_outputs)\n",
        "        # (bs, n_dec_seq, d_hidn), (bs, n_head, n_dec_seq, n_dec_seq), (bs, n_head, n_dec_seq, n_enc_seq)\n",
        "        return ffn_outputs, self_attn_prob, dec_enc_attn_prob"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_D1OrpDhjdj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "        self.dec_emb = nn.Embedding(self.config.n_dec_vocab, self.config.d_hidden)\n",
        "        sinusoid_table = torch.FloatTensor(get_sinusoid_encoding_table(self.config.n_dec_seq + 1, self.config.d_hidden))\n",
        "        self.pos_emb = nn.Embedding.from_pretrained(sinusoid_table, freeze=True)\n",
        "        self.layers = nn.ModuleList([DecoderLayer(self.config) for _ in range(self.config.n_layer)])\n",
        "    \n",
        "    def forward(self, dec_inputs, enc_inputs, enc_outputs):\n",
        "        positions = torch.arange(dec_inputs.size(1), device=dec_inputs.device, dtype=dec_inputs.dtype).expand(dec_inputs.size(0), dec_inputs.size(1)).contiguous() + 1\n",
        "        pos_mask = dec_inputs.eq(self.config.i_pad)\n",
        "        positions.masked_fill_(pos_mask, 0)\n",
        "    \n",
        "        # (bs, n_dec_seq, d_hidn)\n",
        "        dec_outputs = self.dec_emb(dec_inputs) + self.pos_emb(positions)\n",
        "\n",
        "        # (bs, n_dec_seq, n_dec_seq)\n",
        "        dec_attn_pad_mask = get_attn_pad_mask(dec_inputs, dec_inputs, self.config.i_pad)\n",
        "        # (bs, n_dec_seq, n_dec_seq)\n",
        "        dec_attn_decoder_mask = get_attn_decoder_mask(dec_inputs)\n",
        "        # (bs, n_dec_seq, n_dec_seq)\n",
        "        dec_self_attn_mask = torch.gt((dec_attn_pad_mask + dec_attn_decoder_mask), 0)\n",
        "        # (bs, n_dec_seq, n_enc_seq)\n",
        "        dec_enc_attn_mask = get_attn_pad_mask(dec_inputs, enc_inputs, self.config.i_pad)\n",
        "\n",
        "        self_attn_probs, dec_enc_attn_probs = [], []\n",
        "        for layer in self.layers:\n",
        "            # (bs, n_dec_seq, d_hidn), (bs, n_dec_seq, n_dec_seq), (bs, n_dec_seq, n_enc_seq)\n",
        "            dec_outputs, self_attn_prob, dec_enc_attn_prob = layer(dec_outputs, enc_outputs, dec_self_attn_mask, dec_enc_attn_mask)\n",
        "            self_attn_probs.append(self_attn_prob)\n",
        "            dec_enc_attn_probs.append(dec_enc_attn_prob)\n",
        "        # (bs, n_dec_seq, d_hidn), [(bs, n_dec_seq, n_dec_seq)], [(bs, n_dec_seq, n_enc_seq)]S\n",
        "        return dec_outputs, self_attn_probs, dec_enc_attn_probs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "taX7LjSUhmGW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Transformer(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "\n",
        "        self.encoder = Encoder(self.config)\n",
        "        self.decoder = Decoder(self.config)\n",
        "    \n",
        "    def forward(self, enc_inputs, dec_inputs):\n",
        "        # (bs, n_enc_seq, d_hidn), [(bs, n_head, n_enc_seq, n_enc_seq)]\n",
        "        enc_outputs, enc_self_attn_probs = self.encoder(enc_inputs)\n",
        "        # (bs, n_seq, d_hidn), [(bs, n_head, n_dec_seq, n_dec_seq)], [(bs, n_head, n_dec_seq, n_enc_seq)]\n",
        "        dec_outputs, dec_self_attn_probs, dec_enc_attn_probs = self.decoder(dec_inputs, enc_inputs, enc_outputs)\n",
        "        # (bs, n_dec_seq, n_dec_vocab), [(bs, n_head, n_enc_seq, n_enc_seq)], [(bs, n_head, n_dec_seq, n_dec_seq)], [(bs, n_head, n_dec_seq, n_enc_seq)]\n",
        "        return dec_outputs, enc_self_attn_probs, dec_self_attn_probs, dec_enc_attn_probs\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HfcpM22tjXf8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "outputId": "0b4191a8-bd71-428d-a19a-005a7bbfee7d"
      },
      "source": [
        "# prepare_train(vocab, \"<path of data>/ratings_train.txt\", \"<path of data>/ratings_train.json\")\n",
        "# prepare_train(vocab, \"<path of data>/ratings_test.txt\", \"<path of data>/ratings_test.json\")\n",
        "!ls"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "attention_from_master_\t\t\t\t      naver_news_csv.py\n",
            "kowiki\t\t\t\t\t\t      ratings_test.txt\n",
            "kowiki-latest-pages-meta-current.xml.bz2v6ldi9cr.tmp  ratings_train.txt\n",
            "kowiki.model\t\t\t\t\t      README.md\n",
            "kowiki.py\t\t\t\t\t      stackoverflow.py\n",
            "kowiki.vocab\t\t\t\t\t      WikiExtractor.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ESV4NPL3k4gA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "93f34a4f-5739-4581-d0fe-9ea5ae0214f0"
      },
      "source": [
        "Transformer(config)"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Transformer(\n",
              "  (encoder): Encoder(\n",
              "    (enc_emb): Embedding(8007, 256)\n",
              "    (pos_emb): Embedding(257, 256)\n",
              "    (layers): ModuleList(\n",
              "      (0): EncoderLayer(\n",
              "        (self_attn): multi_head_attention(\n",
              "          (W_Q): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (W_K): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (W_V): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (W_0): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (sdpa): scaled_dot_product_attention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (layer_norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "        (pos_ffn): PoswiseFeedForwardNet(\n",
              "          (conv1): Conv1d(256, 1024, kernel_size=(1,), stride=(1,))\n",
              "          (conv2): Conv1d(1024, 256, kernel_size=(1,), stride=(1,))\n",
              "        )\n",
              "        (layer_norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "      )\n",
              "      (1): EncoderLayer(\n",
              "        (self_attn): multi_head_attention(\n",
              "          (W_Q): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (W_K): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (W_V): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (W_0): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (sdpa): scaled_dot_product_attention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (layer_norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "        (pos_ffn): PoswiseFeedForwardNet(\n",
              "          (conv1): Conv1d(256, 1024, kernel_size=(1,), stride=(1,))\n",
              "          (conv2): Conv1d(1024, 256, kernel_size=(1,), stride=(1,))\n",
              "        )\n",
              "        (layer_norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "      )\n",
              "      (2): EncoderLayer(\n",
              "        (self_attn): multi_head_attention(\n",
              "          (W_Q): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (W_K): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (W_V): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (W_0): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (sdpa): scaled_dot_product_attention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (layer_norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "        (pos_ffn): PoswiseFeedForwardNet(\n",
              "          (conv1): Conv1d(256, 1024, kernel_size=(1,), stride=(1,))\n",
              "          (conv2): Conv1d(1024, 256, kernel_size=(1,), stride=(1,))\n",
              "        )\n",
              "        (layer_norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "      )\n",
              "      (3): EncoderLayer(\n",
              "        (self_attn): multi_head_attention(\n",
              "          (W_Q): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (W_K): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (W_V): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (W_0): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (sdpa): scaled_dot_product_attention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (layer_norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "        (pos_ffn): PoswiseFeedForwardNet(\n",
              "          (conv1): Conv1d(256, 1024, kernel_size=(1,), stride=(1,))\n",
              "          (conv2): Conv1d(1024, 256, kernel_size=(1,), stride=(1,))\n",
              "        )\n",
              "        (layer_norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "      )\n",
              "      (4): EncoderLayer(\n",
              "        (self_attn): multi_head_attention(\n",
              "          (W_Q): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (W_K): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (W_V): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (W_0): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (sdpa): scaled_dot_product_attention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (layer_norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "        (pos_ffn): PoswiseFeedForwardNet(\n",
              "          (conv1): Conv1d(256, 1024, kernel_size=(1,), stride=(1,))\n",
              "          (conv2): Conv1d(1024, 256, kernel_size=(1,), stride=(1,))\n",
              "        )\n",
              "        (layer_norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "      )\n",
              "      (5): EncoderLayer(\n",
              "        (self_attn): multi_head_attention(\n",
              "          (W_Q): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (W_K): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (W_V): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (W_0): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (sdpa): scaled_dot_product_attention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (layer_norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "        (pos_ffn): PoswiseFeedForwardNet(\n",
              "          (conv1): Conv1d(256, 1024, kernel_size=(1,), stride=(1,))\n",
              "          (conv2): Conv1d(1024, 256, kernel_size=(1,), stride=(1,))\n",
              "        )\n",
              "        (layer_norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (decoder): Decoder(\n",
              "    (dec_emb): Embedding(8007, 256)\n",
              "    (pos_emb): Embedding(257, 256)\n",
              "    (layers): ModuleList(\n",
              "      (0): DecoderLayer(\n",
              "        (self_attn): multi_head_attention(\n",
              "          (W_Q): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (W_K): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (W_V): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (W_0): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (sdpa): scaled_dot_product_attention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (layer_norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "        (dec_enc_attn): multi_head_attention(\n",
              "          (W_Q): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (W_K): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (W_V): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (W_0): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (sdpa): scaled_dot_product_attention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (layer_norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "        (pos_ffn): PoswiseFeedForwardNet(\n",
              "          (conv1): Conv1d(256, 1024, kernel_size=(1,), stride=(1,))\n",
              "          (conv2): Conv1d(1024, 256, kernel_size=(1,), stride=(1,))\n",
              "        )\n",
              "        (layer_norm3): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "      )\n",
              "      (1): DecoderLayer(\n",
              "        (self_attn): multi_head_attention(\n",
              "          (W_Q): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (W_K): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (W_V): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (W_0): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (sdpa): scaled_dot_product_attention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (layer_norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "        (dec_enc_attn): multi_head_attention(\n",
              "          (W_Q): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (W_K): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (W_V): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (W_0): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (sdpa): scaled_dot_product_attention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (layer_norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "        (pos_ffn): PoswiseFeedForwardNet(\n",
              "          (conv1): Conv1d(256, 1024, kernel_size=(1,), stride=(1,))\n",
              "          (conv2): Conv1d(1024, 256, kernel_size=(1,), stride=(1,))\n",
              "        )\n",
              "        (layer_norm3): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "      )\n",
              "      (2): DecoderLayer(\n",
              "        (self_attn): multi_head_attention(\n",
              "          (W_Q): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (W_K): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (W_V): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (W_0): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (sdpa): scaled_dot_product_attention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (layer_norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "        (dec_enc_attn): multi_head_attention(\n",
              "          (W_Q): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (W_K): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (W_V): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (W_0): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (sdpa): scaled_dot_product_attention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (layer_norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "        (pos_ffn): PoswiseFeedForwardNet(\n",
              "          (conv1): Conv1d(256, 1024, kernel_size=(1,), stride=(1,))\n",
              "          (conv2): Conv1d(1024, 256, kernel_size=(1,), stride=(1,))\n",
              "        )\n",
              "        (layer_norm3): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "      )\n",
              "      (3): DecoderLayer(\n",
              "        (self_attn): multi_head_attention(\n",
              "          (W_Q): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (W_K): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (W_V): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (W_0): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (sdpa): scaled_dot_product_attention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (layer_norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "        (dec_enc_attn): multi_head_attention(\n",
              "          (W_Q): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (W_K): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (W_V): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (W_0): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (sdpa): scaled_dot_product_attention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (layer_norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "        (pos_ffn): PoswiseFeedForwardNet(\n",
              "          (conv1): Conv1d(256, 1024, kernel_size=(1,), stride=(1,))\n",
              "          (conv2): Conv1d(1024, 256, kernel_size=(1,), stride=(1,))\n",
              "        )\n",
              "        (layer_norm3): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "      )\n",
              "      (4): DecoderLayer(\n",
              "        (self_attn): multi_head_attention(\n",
              "          (W_Q): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (W_K): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (W_V): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (W_0): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (sdpa): scaled_dot_product_attention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (layer_norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "        (dec_enc_attn): multi_head_attention(\n",
              "          (W_Q): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (W_K): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (W_V): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (W_0): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (sdpa): scaled_dot_product_attention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (layer_norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "        (pos_ffn): PoswiseFeedForwardNet(\n",
              "          (conv1): Conv1d(256, 1024, kernel_size=(1,), stride=(1,))\n",
              "          (conv2): Conv1d(1024, 256, kernel_size=(1,), stride=(1,))\n",
              "        )\n",
              "        (layer_norm3): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "      )\n",
              "      (5): DecoderLayer(\n",
              "        (self_attn): multi_head_attention(\n",
              "          (W_Q): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (W_K): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (W_V): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (W_0): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (sdpa): scaled_dot_product_attention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (layer_norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "        (dec_enc_attn): multi_head_attention(\n",
              "          (W_Q): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (W_K): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (W_V): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (W_0): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (sdpa): scaled_dot_product_attention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (layer_norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "        (pos_ffn): PoswiseFeedForwardNet(\n",
              "          (conv1): Conv1d(256, 1024, kernel_size=(1,), stride=(1,))\n",
              "          (conv2): Conv1d(1024, 256, kernel_size=(1,), stride=(1,))\n",
              "        )\n",
              "        (layer_norm3): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "43VENX_4iLG-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 379
        },
        "outputId": "befe6b72-62d6-4920-c757-8c0d82f4fb19"
      },
      "source": [
        "# 5/12 이것을 하나하나 뜯어보자...\n",
        "class MovieClassification(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "\n",
        "        self.transformer = Transformer(self.config)\n",
        "        self.projection = nn.Linear(self.config.d_hidn, self.config.n_output, bias=False)\n",
        "    \n",
        "    def forward(self, enc_inputs, dec_inputs):\n",
        "        # (bs, n_dec_seq, d_hidn), [(bs, n_head, n_enc_seq, n_enc_seq)], [(bs, n_head, n_dec_seq, n_dec_seq)], [(bs, n_head, n_dec_seq, n_enc_seq)]\n",
        "        dec_outputs, enc_self_attn_probs, dec_self_attn_probs, dec_enc_attn_probs = self.transformer(enc_inputs, dec_inputs)\n",
        "        # (bs, d_hidn)\n",
        "        dec_outputs, _ = torch.max(dec_outputs, dim=1)\n",
        "        # (bs, n_output)\n",
        "        logits = self.projection(dec_outputs)\n",
        "        # (bs, n_output), [(bs, n_head, n_enc_seq, n_enc_seq)], [(bs, n_head, n_dec_seq, n_dec_seq)], [(bs, n_head, n_dec_seq, n_enc_seq)]\n",
        "        return logits, enc_self_attn_probs, dec_self_attn_probs, dec_enc_attn_probs\n",
        "class MovieDataSet(torch.utils.data.Dataset):\n",
        "    def __init__(self, vocab, infile):\n",
        "        self.vocab = vocab\n",
        "        self.labels = []\n",
        "        self.sentences = []\n",
        "\n",
        "        line_cnt = 0\n",
        "        with open(infile, \"r\") as f:\n",
        "            for line in f:\n",
        "                line_cnt += 1\n",
        "\n",
        "        with open(infile, \"r\") as f:\n",
        "            for i, line in enumerate(tqdm(f, total=line_cnt, desc=f\"Loading {infile}\", unit=\" lines\")):\n",
        "                data = json.loads(line)\n",
        "                self.labels.append(data[\"label\"])\n",
        "                self.sentences.append([vocab.piece_to_id(p) for p in data[\"doc\"]])\n",
        "    \n",
        "    def __len__(self):\n",
        "        assert len(self.labels) == len(self.sentences)\n",
        "        return len(self.labels)\n",
        "    \n",
        "    def __getitem__(self, item):\n",
        "        return (torch.tensor(self.labels[item]),\n",
        "                torch.tensor(self.sentences[item]),\n",
        "                torch.tensor([self.vocab.piece_to_id(\"[BOS]\")]))\n",
        "def movie_collate_fn(inputs):\n",
        "    labels, enc_inputs, dec_inputs = list(zip(*inputs))\n",
        "\n",
        "    enc_inputs = torch.nn.utils.rnn.pad_sequence(enc_inputs, batch_first=True, padding_value=0)\n",
        "    dec_inputs = torch.nn.utils.rnn.pad_sequence(dec_inputs, batch_first=True, padding_value=0)\n",
        "\n",
        "    batch = [\n",
        "        torch.stack(labels, dim=0),\n",
        "        enc_inputs,\n",
        "        dec_inputs,\n",
        "    ]\n",
        "    return batch\n",
        "batch_size = 128\n",
        "train_dataset = MovieDataSet(vocab, \"./ratings_train.json\")\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=movie_collate_fn)\n",
        "test_dataset = MovieDataSet(vocab, \"./ratings_test.json\")\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=movie_collate_fn)\n"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-95-c3ccbc3ec568>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMovieDataSet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"./ratings_train.json\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0mtrain_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmovie_collate_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0mtest_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMovieDataSet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"./ratings_test.json\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-95-c3ccbc3ec568>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, vocab, infile)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mline_cnt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                 \u001b[0mline_cnt\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './ratings_train.json'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6apf5-30irkQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" 모델 epoch 평가 \"\"\"\n",
        "def eval_epoch(config, model, data_loader):\n",
        "    matchs = []\n",
        "    model.eval()\n",
        "\n",
        "    n_word_total = 0\n",
        "    n_correct_total = 0\n",
        "    with tqdm(total=len(data_loader), desc=f\"Valid\") as pbar:\n",
        "        for i, value in enumerate(data_loader):\n",
        "            labels, enc_inputs, dec_inputs = map(lambda v: v.to(config.device), value)\n",
        "\n",
        "            outputs = model(enc_inputs, dec_inputs)\n",
        "            logits = outputs[0]\n",
        "            _, indices = logits.max(1)\n",
        "\n",
        "            match = torch.eq(indices, labels).detach()\n",
        "            matchs.extend(match.cpu())\n",
        "            accuracy = np.sum(matchs) / len(matchs) if 0 < len(matchs) else 0\n",
        "\n",
        "            pbar.update(1)\n",
        "            pbar.set_postfix_str(f\"Acc: {accuracy:.3f}\")\n",
        "    return np.sum(matchs) / len(matchs) if 0 < len(matchs) else 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IoPCkc4MiwF8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_epoch(config, epoch, model, criterion, optimizer, train_loader):\n",
        "    losses = []\n",
        "    model.train()\n",
        "\n",
        "    with tqdm(total=len(train_loader), desc=f\"Train {epoch}\") as pbar:\n",
        "        for i, value in enumerate(train_loader):\n",
        "            labels, enc_inputs, dec_inputs = map(lambda v: v.to(config.device), value)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(enc_inputs, dec_inputs)\n",
        "            logits = outputs[0]\n",
        "\n",
        "            loss = criterion(logits, labels)\n",
        "            loss_val = loss.item()\n",
        "            losses.append(loss_val)\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            pbar.update(1)\n",
        "            pbar.set_postfix_str(f\"Loss: {loss_val:.3f} ({np.mean(losses):.3f})\")\n",
        "    return np.mean(losses)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u43WT7_Li2rF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "config.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "config.n_output = 2\n",
        "print(config)\n",
        "\n",
        "learning_rate = 5e-5\n",
        "n_epoch = 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_O8XMfUyi6kf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = MovieClassification(config)\n",
        "model.to(config.device)\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "losses, scores = [], []\n",
        "for epoch in range(n_epoch):\n",
        "    loss = train_epoch(config, epoch, model, criterion, optimizer, train_loader)\n",
        "    score = eval_epoch(config, model, test_loader)\n",
        "\n",
        "    losses.append(loss)\n",
        "    scores.append(score)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}